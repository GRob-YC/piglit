[require]
GLSL >= 1.20
GL_EXT_gpu_shader4

[vertex shader passthrough]

[fragment shader]
#version 120
#extension GL_EXT_gpu_shader4: require

/* Adapted from the nir_opt_algebraic pattern that causes the bug:
 *
 *  step1 = ('ior', ('ishl', u, 16), ('ushr', u, 16))
 *  step2 = ('ior', ('ishl', ('iand', step1, 0x00ff00ff), 8), ('ushr', ('iand', step1, 0xff00ff00), 8))
 *  step3 = ('ior', ('ishl', ('iand', step2, 0x0f0f0f0f), 4), ('ushr', ('iand', step2, 0xf0f0f0f0), 4))
 *  step4 = ('ior', ('ishl', ('iand', step3, 0x33333333), 2), ('ushr', ('iand', step3, 0xcccccccc), 2))
 *  step5 = ('ior(many-comm-expr)', ('ishl', ('iand', step4, 0x55555555), 1), ('ushr', ('iand', step4, 0xaaaaaaaa), 1))
 *
 *  return step5
 *
 * The problem was that this optimization triggered even on GPUs (e.g., Intel
 * Sandybridge) that lack a BFREV instruction.
 */
unsigned int reverse(unsigned int u)
{
    unsigned int step1 = (u << 16) | (u >> 16);
    unsigned int step2 = ((step1 & 0x00ff00ffu) << 8) | ((step1 & 0xff00ff00u) >> 8);
    unsigned int step3 = ((step2 & 0x0f0f0f0fu) << 4) | ((step2 & 0xf0f0f0f0u) >> 4);
    unsigned int step4 = ((step3 & 0x33333333u) << 2) | ((step3 & 0xccccccccu) >> 2);
    unsigned int step5 = ((step4 & 0x55555555u) << 1) | ((step4 & 0xaaaaaaaau) >> 1);

    return step5;
}

out vec4 piglit_fragcolor;

uniform unsigned int value;
uniform unsigned int expected;

void main()
{
    piglit_fragcolor = (reverse(value) != expected)
        ? vec4(1.0, 0.0, 0.0, 1.0)
        : vec4(0.0, 1.0, 0.0, 1.0);
}

[test]
uniform uint value    0x12345678
uniform uint expected 0x1e6a2c48

draw rect -1 -1 2 2
probe all rgba 0.0 1.0 0.0 1.0
